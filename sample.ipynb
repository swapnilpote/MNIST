{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil, csv, os, numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.optimizers import Adam, RMSprop, SGD, Adagrad\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "# path = 'data/sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "    1. Create train, valid and sample folders\n",
    "    2. Move images into train, valid and sample sub folders\n",
    "    3. Build neural network\n",
    "    4. Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train, valid and sample folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('data/train.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    \n",
    "    for row in reader:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0.png', '4'],\n",
       " ['1.png', '9'],\n",
       " ['2.png', '1'],\n",
       " ['3.png', '7'],\n",
       " ['4.png', '3']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path + 'valid')\n",
    "os.mkdir(path + 'sample')\n",
    "os.mkdir(path + 'sample/train')\n",
    "os.mkdir(path + 'sample/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sub folder for categories in train folder\n",
    "for i in range(len(data)):\n",
    "    if not os.path.isdir(path + 'train/' + data[i][1]):\n",
    "        os.makedirs(path + 'train/' + data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sub folder for categories in valid folder\n",
    "for i in range(len(data)):\n",
    "    if not os.path.isdir(path + 'valid/' + data[i][1]):\n",
    "        os.makedirs(path + 'valid/' + data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sub folder for categories in sample/train folder\n",
    "for i in range(len(data)):\n",
    "    if not os.path.isdir(path + 'sample/train/' + data[i][1]):\n",
    "        os.makedirs(path + 'sample/train/' + data[i][1])\n",
    "        \n",
    "        \n",
    "# Create sub folder for categories in valid folder\n",
    "for i in range(len(data)):\n",
    "    if not os.path.isdir(path + 'sample/valid/' + data[i][1]):\n",
    "        os.makedirs(path + 'sample/valid/' + data[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move images into train, valid and sample sub folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images from train folder into subfolder\n",
    "for i in range(len(data)):\n",
    "    shutil.move(path + 'train/' + data[i][0], path + 'train/' + data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images from train/* folder into valid/*\n",
    "dir_names = [i for i in os.listdir(path + 'train/') if os.path.isdir(os.path.join(path + 'train', i))]\n",
    "\n",
    "for d in dir_names:\n",
    "    g = glob(path + 'train/' + d + '/' + '*.png')\n",
    "    shuf = np.random.permutation(g)\n",
    "    \n",
    "    for i in range(int(len(g) / 5)): shutil.move(shuf[i], path + 'valid/' + d +'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images from train/* folder into sample/train/*\n",
    "dir_names = [i for i in os.listdir(path + 'train/') if os.path.isdir(os.path.join(path + 'train', i))]\n",
    "\n",
    "for d in dir_names:\n",
    "    g = glob(path + 'train/' + d + '/' + '*.png')\n",
    "    shuf = np.random.permutation(g)\n",
    "    \n",
    "    for i in range(int(len(g) / 10)): shutil.copy2(shuf[i], path + 'sample/train/' + d +'/')\n",
    "        \n",
    "        \n",
    "# Move images from valid/* folder into sample/valid/*\n",
    "dir_names = [i for i in os.listdir(path + 'valid/') if os.path.isdir(os.path.join(path + 'valid', i))]\n",
    "\n",
    "for d in dir_names:\n",
    "    g = glob(path + 'valid/' + d + '/' + '*.png')\n",
    "    shuf = np.random.permutation(g)\n",
    "    \n",
    "    for i in range(int(len(g) / 10)): shutil.copy2(shuf[i], path + 'sample/valid/' + d +'/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = cv2.imread('data/train/0/14.png')\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '2', '1', '5', '7', '8', '4', '3', '9', '6']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(path, 'train/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(path + 'train/'):\n",
    "    for file in os.listdir(path + 'train/' + folder + '/'):\n",
    "        if os.path.isfile(path + 'train/' + folder + '/' + file):\n",
    "            \n",
    "            input_img = cv2.imread(path + 'train/' + folder + '/' + file)\n",
    "            input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "            input_img_flatten = cv2.resize(input_img, (28, 28)).flatten()\n",
    "            X_train.append(input_img_flatten)\n",
    "            \n",
    "            y_cat = np_utils.to_categorical(int(folder), 10) # 10 represent number of classed\n",
    "            y_train.append(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39205, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39205, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = []\n",
    "y_valid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(path + 'valid/'):\n",
    "    for file in os.listdir(path + 'valid/' + folder + '/'):\n",
    "        if os.path.isfile(path + 'valid/' + folder + '/' + file):\n",
    "            \n",
    "            input_img = cv2.imread(path + 'valid/' + folder + '/' + file)\n",
    "            input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "            input_img_flatten = cv2.resize(input_img, (28, 28)).flatten()\n",
    "            \n",
    "            X_valid.append(input_img_flatten)\n",
    "            \n",
    "            y_cat = np_utils.to_categorical(int(folder), 10) # 10 represent number of classed\n",
    "            y_valid.append(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.asarray(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = np.asarray(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9795, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9795, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = 784, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 125,770\n",
      "Trainable params: 125,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39205 samples, validate on 9795 samples\n",
      "Epoch 1/10\n",
      "39205/39205 [==============================] - 24s 602us/step - loss: 9.1670 - acc: 0.4269 - val_loss: 8.4978 - val_acc: 0.4721\n",
      "Epoch 2/10\n",
      "39205/39205 [==============================] - 5s 131us/step - loss: 8.8505 - acc: 0.4501 - val_loss: 8.9892 - val_acc: 0.4421\n",
      "Epoch 3/10\n",
      "39205/39205 [==============================] - 5s 125us/step - loss: 8.7384 - acc: 0.4574 - val_loss: 8.7609 - val_acc: 0.4564\n",
      "Epoch 4/10\n",
      "39205/39205 [==============================] - 5s 126us/step - loss: 9.0788 - acc: 0.4365 - val_loss: 8.8069 - val_acc: 0.4532\n",
      "Epoch 5/10\n",
      "39205/39205 [==============================] - 5s 129us/step - loss: 9.1889 - acc: 0.4297 - val_loss: 10.3095 - val_acc: 0.3603\n",
      "Epoch 6/10\n",
      "39205/39205 [==============================] - 5s 125us/step - loss: 9.1593 - acc: 0.4316 - val_loss: 9.0232 - val_acc: 0.4399\n",
      "Epoch 7/10\n",
      "39205/39205 [==============================] - 5s 131us/step - loss: 8.6674 - acc: 0.4622 - val_loss: 8.7658 - val_acc: 0.4562\n",
      "Epoch 8/10\n",
      "39205/39205 [==============================] - 5s 126us/step - loss: 9.5226 - acc: 0.4091 - val_loss: 8.5107 - val_acc: 0.4720\n",
      "Epoch 9/10\n",
      "39205/39205 [==============================] - 5s 129us/step - loss: 8.9667 - acc: 0.4436 - val_loss: 9.0444 - val_acc: 0.4387\n",
      "Epoch 10/10\n",
      "39205/39205 [==============================] - 5s 128us/step - loss: 9.0873 - acc: 0.4362 - val_loss: 8.8695 - val_acc: 0.4497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa2abbd30b8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, batch_size = batch_size, validation_data = [X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights/fully_connected.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(path + 'train/'):\n",
    "    for file in os.listdir(path + 'train/' + folder + '/'):\n",
    "        if os.path.isfile(path + 'train/' + folder + '/' + file):\n",
    "            \n",
    "            input_img = cv2.imread(path + 'train/' + folder + '/' + file)\n",
    "            # input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "            input_img = cv2.resize(input_img, (28, 28))\n",
    "            X_train.append(input_img)\n",
    "            \n",
    "            y_cat = np_utils.to_categorical(int(folder), 10) # 10 represent number of classed\n",
    "            y_train.append(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39205, 28, 28, 3)\n",
      "(39205, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = []\n",
    "y_valid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(path + 'valid/'):\n",
    "    for file in os.listdir(path + 'valid/' + folder + '/'):\n",
    "        if os.path.isfile(path + 'valid/' + folder + '/' + file):\n",
    "            \n",
    "            input_img = cv2.imread(path + 'valid/' + folder + '/' + file)\n",
    "            input_img_flatten = cv2.resize(input_img, (28, 28))\n",
    "            \n",
    "            X_valid.append(input_img_flatten)\n",
    "            \n",
    "            y_cat = np_utils.to_categorical(int(folder), 10) # 10 represent number of classed\n",
    "            y_valid.append(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.asarray(X_valid)\n",
    "y_valid = np.asarray(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9795, 28, 28, 3)\n",
      "(9795, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(28, 28, 3), padding='same', activation='relu'))\n",
    "model.add(Convolution2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Convolution2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Convolution2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 997,546\n",
      "Trainable params: 997,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39205 samples, validate on 9795 samples\n",
      "Epoch 1/10\n",
      "39205/39205 [==============================] - 16s 416us/step - loss: 0.4641 - acc: 0.9070 - val_loss: 0.0742 - val_acc: 0.9771\n",
      "Epoch 2/10\n",
      "39205/39205 [==============================] - 11s 269us/step - loss: 0.0674 - acc: 0.9806 - val_loss: 0.0617 - val_acc: 0.9820\n",
      "Epoch 3/10\n",
      "39205/39205 [==============================] - 10s 264us/step - loss: 0.0496 - acc: 0.9853 - val_loss: 0.0657 - val_acc: 0.9821\n",
      "Epoch 4/10\n",
      "39205/39205 [==============================] - 10s 264us/step - loss: 0.0424 - acc: 0.9878 - val_loss: 0.0642 - val_acc: 0.9825\n",
      "Epoch 5/10\n",
      "39205/39205 [==============================] - 10s 266us/step - loss: 0.0356 - acc: 0.9892 - val_loss: 0.0589 - val_acc: 0.9862\n",
      "Epoch 6/10\n",
      "39205/39205 [==============================] - 10s 267us/step - loss: 0.0373 - acc: 0.9897 - val_loss: 0.0506 - val_acc: 0.9867\n",
      "Epoch 7/10\n",
      "39205/39205 [==============================] - 10s 267us/step - loss: 0.0379 - acc: 0.9898 - val_loss: 0.0560 - val_acc: 0.9895\n",
      "Epoch 8/10\n",
      "39205/39205 [==============================] - 11s 274us/step - loss: 0.0312 - acc: 0.9908 - val_loss: 0.0662 - val_acc: 0.9860\n",
      "Epoch 9/10\n",
      "39205/39205 [==============================] - 11s 278us/step - loss: 0.0323 - acc: 0.9910 - val_loss: 0.0443 - val_acc: 0.9894\n",
      "Epoch 10/10\n",
      "39205/39205 [==============================] - 11s 278us/step - loss: 0.0281 - acc: 0.9926 - val_loss: 0.0622 - val_acc: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa29be4e9e8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, batch_size = batch_size, validation_data = [X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(path + \"results/conv_e10.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(path + \"results/conv_e10.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open(path + 'results/conv_e10.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(path + \"results/conv_e10.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
